{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples = 500, noise=0.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf),('rf', rnd_clf),('svm', svm_clf)],\n",
    "    voting = 'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)), ('rf', RandomFo...f', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "SVC 0.888\n",
      "RandomForestClassifier 0.912\n",
      "VotingClassifier 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, svm_clf, rnd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "SVC 0.888\n",
      "RandomForestClassifier 0.888\n",
      "VotingClassifier 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nana\\anaconda3\\envs\\ml-learn-3.5\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf),('rf', rnd_clf),('svm', svm_clf)],\n",
    "    voting = 'soft'\n",
    ")\n",
    "\n",
    "for clf in (log_clf, svm_clf, rnd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_predict = bag_clf.predict(X_test)\n",
    "print(bag_clf.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8986666666666666\n",
      "BaggingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "bag_clf2 = BaggingClassifier(DecisionTreeClassifier(),n_estimators=500, bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "bag_clf2.fit(X_train, y_train)\n",
    "y_predict = bag_clf2.predict(X_test)\n",
    "print(bag_clf2.oob_score_)\n",
    "print(bag_clf2.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500, n_jobs=-1, max_leaf_nodes=16 )\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_predict = rnd_clf.predict(X_test)\n",
    "print(rnd_clf.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "bag_clf3 = BaggingClassifier(\n",
    "        DecisionTreeClassifier(splitter='random', max_leaf_nodes=16), n_estimators=500, n_jobs=-1, max_samples=1.0, bootstrap=True)\n",
    "bag_clf3.fit(X_train, y_train)\n",
    "y_predict = bag_clf3.predict(X_test)\n",
    "print(bag_clf3.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm='SAMME.R', learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_predict = ada_clf.predict(X_test)\n",
    "print(ada_clf.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08239669753072186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "y_predict = gbrt.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22535136085701532, 0.20464249946397559, 0.18619003481916896, 0.1729699538388438, 0.16275993123567267, 0.1528150048606917, 0.1465039859755851, 0.14006856124133513, 0.13630300630792605, 0.13219457560859418, 0.13004174699639753, 0.1278676956951201]\n",
      "0.13004174699639756\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=12)\n",
    "gbrt.fit(X_train, y_train)\n",
    "errors = [mean_squared_error(y_val,y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "print(errors)\n",
    "err_n = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=err_n)\n",
    "gbrt_best.fit(X_train, y_train)\n",
    "y_predict = gbrt_best.predict(X_val)\n",
    "print(mean_squared_error(y_val, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_err = float('inf')\n",
    "going = 0\n",
    "for n_estimators in range(1,1000):\n",
    "    grbt.n_estimators = n_estimators\n",
    "    grbt.fit(X_train, y_train)\n",
    "    y_predict = grbt.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_predict)\n",
    "    if error < min_err:\n",
    "        min_err = error\n",
    "        going = 0\n",
    "    else:\n",
    "        going += 1\n",
    "        if going > 5:\n",
    "            break;\n",
    "print(grbt.n_estimators)\n",
    "# y_p = grbt\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
